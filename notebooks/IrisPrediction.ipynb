{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asking the right Question?\n",
    "Use the Machine Learning Workflow to process and transform Iris data to create a prediction model.\n",
    "This Model must predict what type of iris likely to be with 70% or greater accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Do ploting inline istead of in a seperate window\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load Iris Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris FEATURES shape\n",
      "(150, 4)\n",
      "\n",
      "Iris TARGET shape\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()\n",
    "X_iris = iris_dataset.data  # X is uppercase b/c it is matrix\n",
    "y_iris = iris_dataset.target # y is lowercase b/c it is vector\n",
    "\n",
    "print(\"Iris FEATURES shape\")\n",
    "print(X_iris.shape)\n",
    "print(\"\\nIris TARGET shape\")\n",
    "print(y_iris.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Definition of features: \n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "\n",
      "5 head of the feature data\n",
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]]\n"
     ]
    }
   ],
   "source": [
    "print(\"The Definition of features: \\n{0}\\n\".format(iris_dataset.feature_names))\n",
    "print(\"5 head of the feature data\")\n",
    "print(X_iris[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row is observer which is sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 head of the target data\n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"5 head of the target data\")\n",
    "print(y_iris[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check  setosa/versicolor/virginica ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sectosa: 50 (33.33%)\n",
      "Number of versicolor: 50 (33.33%)\n",
      "Number of virginica: 50 (33.33%)\n"
     ]
    }
   ],
   "source": [
    "num_sectosa = len(list(filter(lambda x: x == 0, y_iris)))\n",
    "num_versicolor = len(list(filter(lambda x: x == 1, y_iris)))\n",
    "num_virginica = len(list(filter(lambda x: x == 2, y_iris)))\n",
    "\n",
    "print(\"Number of sectosa: {0} ({1:2.2f}%)\".format(num_sectosa, num_sectosa/len(y_iris) * 100))\n",
    "print(\"Number of versicolor: {0} ({1:2.2f}%)\".format(num_versicolor, num_sectosa/len(y_iris) * 100))\n",
    "print(\"Number of virginica: {0} ({1:2.2f}%)\".format(num_virginica, num_sectosa/len(y_iris) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data (Data is ready to use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the Initial Algorithms\n",
    "\n",
    "Role of algorithm\n",
    "    - Use solution statement filter algorithms\n",
    "    - Discuss best algorithms\n",
    "    - Select one initial algorithm\n",
    "        - Learning Type => Prediction Model => Supervised ML\n",
    "        - Result\n",
    "            - Regression\n",
    "            - *Classification\n",
    "        - Complexity\n",
    "            - *Simple\n",
    "            - Ensemble algorithms\n",
    "        - *Basic vs enhanced\n",
    "    \n",
    "There are over 50 algorithms in scikit-learn\n",
    "    - Supervised ML algorithms: 28 \n",
    "        - Regression: 8\n",
    "        - Classifiction (Maybe Both): 20\n",
    "            - Basic & Enhanced algorithms: 14\n",
    "    - Others: 22\n",
    "\n",
    "Based on above information, I am going to chose two simple initial algorithms\n",
    "    1. KNN\n",
    "    2. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data\n",
    "\n",
    "70% for traing, 30% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "split_test_size = 0.30\n",
    "# random_state (could be any number) gurantees the split is always going to be the same when it splits the data again\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_iris, y_iris, test_size = split_test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check to ensure we have the desired 70% train  and 30% test split of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.00% in training set\n",
      "30.00% in test set\n"
     ]
    }
   ],
   "source": [
    "print(\"{0:.2f}% in training set\".format(len(X_train)/len(X_iris)*100))\n",
    "print(\"{0:.2f}% in test set\".format(len(X_test)/len(X_iris)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying predicted value was split correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sectosa: 50 (33.33%)\n",
      "Original versicolor: 50 (33.33%)\n",
      "Original virginica: 50 (33.33%)\n",
      "Original total: 150\n",
      "\n",
      "Training sectosa: 31 (29.52%)\n",
      "Training versicolor: 37 (35.24%)\n",
      "Training virginica: 37 (24.67%)\n",
      "Training total: 105 (70.00%)\n",
      "\n",
      "Test sectosa: 19 (42.22%)\n",
      "Test versicolor: 13 (28.89%)\n",
      "Test virginica: 13 (28.89%)\n",
      "Test total: 45 (30.00%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original sectosa: {0} ({1:2.2f}%)\".format(num_sectosa, num_sectosa/len(X_iris) * 100))\n",
    "print(\"Original versicolor: {0} ({1:2.2f}%)\".format(num_versicolor, num_versicolor/len(X_iris) * 100))\n",
    "print(\"Original virginica: {0} ({1:2.2f}%)\".format(num_virginica, num_virginica/len(X_iris) * 100))\n",
    "print(\"Original total: {0}\".format(len(X_iris)))\n",
    "print(\"\")\n",
    "\n",
    "num_sectosa_train = len(list(filter(lambda x: x == 0, y_train)))\n",
    "num_versicolor_train = len(list(filter(lambda x: x == 1, y_train)))\n",
    "num_virginica_train = len(list(filter(lambda x: x == 2, y_train)))\n",
    "\n",
    "print(\"Training sectosa: {0} ({1:2.2f}%)\".format(num_sectosa_train, num_sectosa_train/len(y_train) * 100))\n",
    "print(\"Training versicolor: {0} ({1:2.2f}%)\".format(num_versicolor_train, num_versicolor_train/len(y_train) * 100))\n",
    "print(\"Training virginica: {0} ({1:2.2f}%)\".format(num_virginica_train, num_virginica_train/len(X_iris) * 100))\n",
    "print(\"Training total: {0} ({1:2.2f}%)\".format(len(y_train), len(y_train)/len(X_iris) * 100))\n",
    "print(\"\")\n",
    "\n",
    "num_sectosa_test = len(list(filter(lambda x: x == 0, y_test)))\n",
    "num_versicolor_test = len(list(filter(lambda x: x == 1, y_test)))\n",
    "num_virginica_test = len(list(filter(lambda x: x == 2, y_test)))\n",
    "\n",
    "print(\"Test sectosa: {0} ({1:2.2f}%)\".format(num_sectosa_test, num_sectosa_test/len(y_test) * 100))\n",
    "print(\"Test versicolor: {0} ({1:2.2f}%)\".format(num_versicolor_test, num_versicolor_test/len(y_test) * 100))\n",
    "print(\"Test virginica: {0} ({1:2.2f}%)\".format(num_virginica_test, num_virginica_test/len(y_test) * 100))\n",
    "print(\"Test total: {0} ({1:2.2f}%)\".format(len(y_test), len(y_test)/len(X_iris) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training KNN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# n_neighbors is one of regularization hyperparameters\n",
    "knn_model = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance on training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9524\n"
     ]
    }
   ],
   "source": [
    "# import the performance metrics library from scikit-learn\n",
    "from sklearn import metrics\n",
    "\n",
    "knn_predict_train = knn_model.predict(X_train)\n",
    "\n",
    "# Accuracy\n",
    "print(\"Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_train, knn_predict_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! KNN algorithm learnt the training data too well which causes the overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance on test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "knn_predict_test = knn_model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print(\"Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_test, knn_predict_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confussion Matrix\n",
      "[[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confussion Matrix\")\n",
    "print(metrics.confusion_matrix(y_test, knn_predict_test, labels=[0,1,2]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It is a perfect classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confussion Matrix\n",
    "\n",
    "    [[TP,FP]\n",
    "     [FN, TN]]\n",
    "     \n",
    "    - TP: Predicted = yes, Actual = yes\n",
    "    - FP: Predicted = yes, Actual = no\n",
    "    - FN: Predicted = no,  Actual = yes\n",
    "    - TN: Predicted = no, Actual  = no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      1.00      1.00        13\n",
      "          2       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, knn_predict_test, labels=[0,1,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically\n",
    "    - recall: TP/(TP+FN)\n",
    "    - precision: TP/(TP+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Logistis Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\\\n",
    "\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Performance on training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9619\n",
      "\n",
      "Metrics\n",
      "Confussion matrix\n",
      "[[31  0  0]\n",
      " [ 0 33  4]\n",
      " [ 0  0 37]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        31\n",
      "          1       1.00      0.89      0.94        37\n",
      "          2       0.90      1.00      0.95        37\n",
      "\n",
      "avg / total       0.97      0.96      0.96       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_predict_train = lr_model.predict(X_train)\n",
    "\n",
    "# Test metrics\n",
    "# Accuracy\n",
    "print(\"Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_train, lr_predict_train)))\n",
    "print(\"\")\n",
    "print(\"Metrics\")\n",
    "print(\"Confussion matrix\")\n",
    "print(metrics.confusion_matrix(y_train, lr_predict_train, labels=[0,1,2]))\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_train, lr_predict_train, labels=[0,1,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9778\n",
      "\n",
      "Metrics\n",
      "Confussion matrix\n",
      "[[19  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0 13]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      0.92      0.96        13\n",
      "          2       0.93      1.00      0.96        13\n",
      "\n",
      "avg / total       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_predict_test = lr_model.predict(X_test)\n",
    "\n",
    "# Train metrics\n",
    "# Accuracy\n",
    "print(\"Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_test, lr_predict_test)))\n",
    "print(\"\")\n",
    "print(\"Metrics\")\n",
    "print(\"Confussion matrix\")\n",
    "print(metrics.confusion_matrix(y_test, lr_predict_test, labels=[0,1,2]))\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, lr_predict_test, labels=[0,1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
